#### Abstract
Super Resolution has been steaming hot in the industry.  Medicare explored and implementing super resolution to assist in tumor detection, computer gaming industry has been succeeding leveraging super resolution to bring legendary games in low resolution back to the 4k world again.

Therefore in this project, I have studied and implemented the research work from the paper "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network". 

#### Introduction and prior work
Along with previous successor, SRGAN succeeded in super resolution by proposing the first generative and adversarial based networks to generate upscaled images up to 4x upscaling, and nova ideas on loss functions instead of MSE, so the resulted images would not be bounded by tendency of averaging pixels resulting loss of high frequency content.

#### Methods
While having followed most of the framework of the paper, I have used celebrities dataset composed of 178 x 218 sized images instead for training and testing.  The idea is aimed at generating facial pictures with better performance by learning faces.

The framework basically downscale an input image to 1/4 of its size, then pass it to a generator network to upscale the resolution to 4x, then followed by a discriminator network to compare adversarial loss.  

For most of the papers, the testing methodology is to compare a downscaled version of the same image with an upscaled image by bicubic, and also an upscaled image by SRGAN.  

But my goal is to upscale an image with a realistic size instead of comparing it with a downscaled.  Therefore, after getting satisfactory testing results, I tried to upscale a 854 x 862 image to about 3x to 2500 x 2500, to see how do the networks perform.   I hope i could have experimented 4x to further compare the result with Bicubic, but unfortunately the thought was limited by available GPU memory.

#### Results
Original image,  854 x 862. 

<img src = "https://user-images.githubusercontent.com/21034990/192045719-cbb6c7c6-5ad4-483f-9d38-dd037890f75f.png" width = 400>

As a control test, after training and testing with the celebrities dataset, I ran the generator to produce a SRGAN with my own image.

At the left, the original image was transformed to Bicubic.  In the middle, the original image was downscaled to 1/4 of its size (LR).  At the right, result of the generated image by the LR version.

The LR image looks obviously blurred and pixelated.  The SRGAN generated image, when comparing with Bicubic, look sharper with lines.

Bicubic	LR	SRGAN

<img src = "https://user-images.githubusercontent.com/21034990/192046164-c7840c76-00d7-4174-8bd0-fba6788afa8e.png" width = 300>
<img src = "https://user-images.githubusercontent.com/21034990/192046171-613beb22-e107-4853-9879-17507bd4ed47.png" width = 300>
<img src = "https://user-images.githubusercontent.com/21034990/192046187-9e556207-1d0d-4abf-b95c-3916afcf16a8.png" width = 300>





Then I tried to generate a 2500 x 2500 upscaled version (about 3x scaling factor) from 854 x 862.  

The network takes a desired HR height and resized the input image to HR height/4, which is 625 x 625 in this case, then upscale to 2500 x 2500.  

To compare with the result, as shown at the left, the original image was upscaled by Bicubic to 2500 x 2500 while at the right, it's the HR output generated by SRGAN.

Since SRGAN emphasis on texture, it's expected that the generated image is sharper with lines and textures.  We can observe from the concrete structure for richer textures, and overall higher in contrast because of the same reason.

Bicubic	SRGAN
